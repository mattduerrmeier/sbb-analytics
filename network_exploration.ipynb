{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2dac736355eb5cfe",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4891d600f13ba914",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T19:07:17.373850Z",
     "start_time": "2024-04-14T19:07:17.359361Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import permutations\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e8662d72e75692",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# 1. Network Exploration \n",
    "\n",
    "The graph is loaded from the `sbb.edgelist`.\n",
    "Make sure to create this edgelist through the `create_edgelist.py` script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22ca91dce5b440b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T18:03:32.749534Z",
     "start_time": "2024-04-14T18:03:32.302292Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "G = nx.read_edgelist(\"sbb.edgelist\", delimiter=\";\", create_using=nx.Graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7535b07c-f8ab-4fa4-9cab-57067a62a611",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T18:03:32.781368Z",
     "start_time": "2024-04-14T18:03:32.750516Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of nodes: 3473\n",
      "number of edges: 8610\n"
     ]
    }
   ],
   "source": [
    "print(f\"number of nodes: {len(G.nodes)}\")\n",
    "print(f\"number of edges: {len(G.edges)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6550b205-ec2e-46c1-b450-d81e07213480",
   "metadata": {},
   "source": [
    "## Degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "028aa6ff-f1f7-4a73-bbae-bdf09f4dc433",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T18:03:32.781368Z",
     "start_time": "2024-04-14T18:03:32.750516Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min degree: 1\n",
      "number of nodes with degree of 1: 83\n",
      "max degree: 102\n",
      "number of nodes with degree of 102: 1\n",
      "max degree node: Zürich HB\n",
      "75\n"
     ]
    }
   ],
   "source": [
    "degrees = dict(G.degree())\n",
    "\n",
    "# min degree\n",
    "min_deg_node = min(degrees, key=degrees.get)\n",
    "min_deg = min(degrees.values())\n",
    "print(f'min degree: {min_deg}')\n",
    "l_min_deg = {node: degree for (node, degree) in degrees.items() if degree == min_deg}\n",
    "print(f'number of nodes with degree of {min_deg}: {len(l_min_deg)}')\n",
    "\n",
    "# todo: max degree\n",
    "max_deg_node = max(degrees, key=degrees.get)\n",
    "max_deg = max(degrees.values())\n",
    "print(f'max degree: {max_deg}')\n",
    "l_max_deg = {node: degree for (node, degree) in degrees.items() if degree == max_deg}\n",
    "print(f'number of nodes with degree of {max_deg}: {len(l_max_deg)}')\n",
    "print(f'max degree node: {max_deg_node}')\n",
    "\n",
    "print(len(list(G.neighbors('Lyon Part Dieu'))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33050a8a-0428-4763-ac69-450f39cf55b6",
   "metadata": {},
   "source": [
    "## Centrality Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd4770118404b39c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T18:23:17.688180Z",
     "start_time": "2024-04-14T18:22:39.760510Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Basel SBB', 'Mulhouse', 'Genève', 'Bellegarde-sur-Valserine', 'Lyon Part Dieu']\n",
      "['Mühlehorn (See)', 'Fällanden (See)', 'Mönchaltorf (See)', 'Solothurn (Schiff)', 'Rheinau Kraftwerk']\n"
     ]
    }
   ],
   "source": [
    "# Betweeness centrality measures: node is the one that acts as a bridge, broker or gatekeeper.\n",
    "betweenness_centrality = nx.betweenness_centrality(G, normalized=True)\n",
    "\n",
    "# find top 5 betweenness centrality nodes\n",
    "sorted_centrality_node = sorted(betweenness_centrality, key=betweenness_centrality.get, reverse=True)\n",
    "\n",
    "top5_betweenness_centrality = sorted_centrality_node[0:5]\n",
    "bottom5_betweenness_centrality = sorted_centrality_node[-5:]\n",
    "\n",
    "print(top5_betweenness_centrality)\n",
    "print(bottom5_betweenness_centrality)\n",
    "\n",
    "# # todo find all nodes w a betweenness centrality of 0\n",
    "# _centrality_node = min(betweenness_centrality, key=betweenness_centrality.get)\n",
    "# print(f'min betweenness centrality: {min_centrality_node}, {betweenness_centrality[min_centrality_node]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "581607a15a8ccd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T18:23:34.619562Z",
     "start_time": "2024-04-14T18:23:28.996654Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Zürich HB', 'Genève', 'Basel SBB', 'Olten', 'Lausanne']\n",
      "['Horgen Autoquai', 'Les Brenets (Lac)', 'Saut-du-Doubs', 'Gersau Förstli (Fähre)', 'Beckenried Niederdorf (Fähre)']\n"
     ]
    }
   ],
   "source": [
    "# Closeness centrality measure: ceentral node is the one that is close, on average, to other nodes.\n",
    "closeness_centrality = nx.closeness_centrality(G)\n",
    "\n",
    "sorted_closeness_node = sorted(closeness_centrality, key=closeness_centrality.get, reverse=True)\n",
    "\n",
    "top5_closeness_centrality = sorted_closeness_node[0:5]\n",
    "bottom5_closeness_centrality = sorted_closeness_node[-5:]\n",
    "\n",
    "print(top5_closeness_centrality)\n",
    "print(bottom5_closeness_centrality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d410827bdda99eaa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T18:25:17.425924Z",
     "start_time": "2024-04-14T18:24:31.357923Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min sim ['Luzern', 'Laufenburg']: 0, max sim ['Zürich HB', 'Rapperswil SG']: 9.168828484214584\n"
     ]
    }
   ],
   "source": [
    "# Similarity measures\n",
    "perms = list(permutations(G.nodes, 2))\n",
    "\n",
    "# This measure refines the simple counting of vertex similarity by weighting less-connected neighbors more heavily\n",
    "# Two FB persons who are friends with a famous person are (probably) less similar than those who are friends with a less famous person.\n",
    "aa = nx.adamic_adar_index(G, perms)\n",
    "\n",
    "min_sim = np.inf\n",
    "min_sim_u_v = []\n",
    "max_sim = 0\n",
    "max_sim_u_v = []\n",
    "\n",
    "for u, v, p in aa:\n",
    "    if p < min_sim:\n",
    "        min_sim = p\n",
    "        min_sim_u_v = [u,v]\n",
    "    elif p > max_sim:\n",
    "        max_sim = p\n",
    "        max_sim_u_v = [u,v]\n",
    "        \n",
    "print(f'min sim {min_sim_u_v}: {min_sim}, max sim {max_sim_u_v}: {max_sim}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ea25f3-255b-47ca-b8e2-22a3749dd27b",
   "metadata": {},
   "source": [
    "# 2. Community Detection\n",
    "\n",
    "## Louvain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6be874b31ea23a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T19:49:54.073889Z",
     "start_time": "2024-04-14T19:49:23.062372Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "louvain = nx.community.louvain_communities(G, seed=42, resolution=0.5)\n",
    "print(len(louvain))\n",
    "\n",
    "louvain_len = [len(s) for s in louvain]               \n",
    "print(\"Louvain: size of each community:\", louvain_len)             \n",
    "\n",
    "getcolors = lambda n: [\"#%06x\" % random.randint(0, 0xFFFFFF) for _ in range(n)]\n",
    "\n",
    "colors = getcolors(len(louvain))\n",
    "\n",
    "plt.figure(figsize=(12, 10))    \n",
    "pos = nx.spring_layout(G, seed=42)     \n",
    "for i, c in enumerate(louvain):   \n",
    "    nx.draw_networkx_nodes(     \n",
    "        G, pos=pos, nodelist=c, node_color=colors[i], node_size=10, alpha=0.75        \n",
    "    )            \n",
    "\n",
    "nx.draw_networkx_edges(G, pos=pos, width=0.20, alpha=0.33)\n",
    "plt.title(\"Louvain Community Detection\")\n",
    "plt.show()\n",
    "\n",
    "# todo: use edge weights to help visualise the graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5c95ffd71cc61e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T19:51:22.005430Z",
     "start_time": "2024-04-14T19:50:48.803697Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# louvain with largest connected component\n",
    "connected_comp = nx.connected_components(G)\n",
    "max_connected_comp = max(connected_comp)\n",
    "print(\"Number of nodes in largest connected component: \", len(max_connected_comp))\n",
    "\n",
    "sub_G = G.subgraph(max_connected_comp)\n",
    "\n",
    "louvain = nx.community.louvain_communities(sub_G, seed=42, resolution=0.5)\n",
    "print(len(louvain))\n",
    "\n",
    "louvain_len = [len(s) for s in louvain]               \n",
    "print(\"Louvain: size of each community:\", louvain_len)             \n",
    "\n",
    "getcolors = lambda n: [\"#%06x\" % random.randint(0, 0xFFFFFF) for _ in range(n)]\n",
    "\n",
    "colors = getcolors(len(louvain))\n",
    "\n",
    "plt.figure(figsize=(12, 10))    \n",
    "pos = nx.spring_layout(sub_G, seed=42)     \n",
    "for i, c in enumerate(louvain):   \n",
    "    nx.draw_networkx_nodes(     \n",
    "        sub_G, pos=pos, nodelist=c, node_color=colors[i], node_size=10, alpha=0.75        \n",
    "    )            \n",
    "\n",
    "nx.draw_networkx_edges(sub_G, pos=pos, width=0.20, alpha=0.33)\n",
    "plt.title(\"Louvain Community Detection\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da87f4e-8743-4a89-be5c-b2c5486a8a90",
   "metadata": {},
   "source": [
    "## Girvan Newman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd73f6e9dd19edfd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T10:06:08.895474Z",
     "start_time": "2024-04-15T09:24:11.177277Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Girvan Newman\n",
    "\n",
    "# TODO: Apply the Girvan-Newman method from the networkx library iteratively for 30 minutes.\n",
    "gn_communities = nx.community.girvan_newman(sub_G)\n",
    "it = 0\n",
    "i = []\n",
    "timeout = time.time() + 60 * 25 # setting to 30 minutes makes it run for over 1.5 hours, setting to 25 results in a runtime of 31m\n",
    "while True:\n",
    "    if time.time() > timeout:\n",
    "        break\n",
    "    it += 1\n",
    "    i = next(gn_communities, 'end')\n",
    "\n",
    "print(f'number of iterations: {it}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed147daaa6c93d9c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T15:59:12.413365Z",
     "start_time": "2024-04-15T15:58:18.225065Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Report the size of each community and draw the graph. Color the nodes according to their community.\n",
    "\n",
    "getcolors = lambda n: [\"#%06x\" % random.randint(0, 0xFFFFFF) for _ in range(n)]\n",
    "colors = getcolors(len(i))\n",
    "\n",
    "plt.figure(figsize=(12, 10))    \n",
    "pos = nx.spring_layout(sub_G, seed=42)     \n",
    "for idx, c in enumerate(i):\n",
    "    print(f'Size of community {idx+1}: {len(c)}')\n",
    "    nx.draw_networkx_nodes(     \n",
    "        sub_G, pos=pos, nodelist=c, node_color=colors[idx], node_size=10, alpha=0.75        \n",
    "    )            \n",
    "\n",
    "nx.draw_networkx_edges(sub_G, pos=pos, width=0.20, alpha=0.33)\n",
    "plt.title(\"Girvan Newman Community Detection\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
